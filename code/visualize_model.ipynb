{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c17d3d-9cbb-4bb0-a519-14c74908ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5572956-2faa-46f2-9c34-78c5d828fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 12:47:04.695921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 12:47:05.366519: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-02-14 12:47:05.366606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-02-14 12:47:05.366613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# My imports\n",
    "import os\n",
    "from time import time\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from objective_func import macro_soft_f1, macro_f1\n",
    "from loader.mimic_cxr_jpg_loader import MIMIC_CXR_JPG_Loader\n",
    "from utils.augmentation import preprocess_image\n",
    "from lars_optimizer import LARSOptimizer\n",
    "from utils.analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c38bae-5fe0-4a1c-9377-71e23da3e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "project_folder = os.getcwd()\n",
    "BASE_MODEL_PATH = './base-models/simclr/r152_2x_sk1/hub/'\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-6\n",
    "IMAGE_SIZE = (448, 448)\n",
    "CHANNELS = 3\n",
    "num_classes = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6845810-8301-45a2-a0c3-f04e25555c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c21e5d-dba5-4c6a-8ca6-01357689a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850c30bf-bb6e-49c9-af0a-14a2b5e7ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./out/board/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408c4f2-a552-49c2-af23-b05a6d911ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93fbe5c-c872-4e04-bcc3-773fc980fc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 12:47:09.149305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.153401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.153543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.153824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 12:47:09.154821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.154955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.155074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.600140: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.600311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.600493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 12:47:09.600590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 4096)              391961768 \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 1024)              4195328   \n",
      "                                                                 \n",
      " multi-label_classifier (Den  (None, 14)               14350     \n",
      " se)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 396,171,446\n",
      "Trainable params: 4,209,678\n",
      "Non-trainable params: 391,961,768\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hub_path = os.path.join(project_folder, BASE_MODEL_PATH)\n",
    "try:\n",
    "    feature_extractor_layer = hub.KerasLayer(hub_path, input_shape=(*IMAGE_SIZE, CHANNELS), trainable=False)\n",
    "except:\n",
    "    print(f\"\"\"The model {hub_path} did not load. Please verify the model path. It is also worth considering that the model might still be in the process of being uploaded to the designated location. If you have recently uploaded it to a notebook, there could be delays associated with the upload.\"\"\")\n",
    "    raise\n",
    "\n",
    "#------------------- SETUP TRAINING HEAD -------------------#\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    layers.Dense(num_classes, activation='sigmoid', name='multi-label_classifier')\n",
    "])\n",
    "\n",
    "# TEMP for debugging\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b34f3c-032e-4377-a76f-7295eeec6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY)\n",
    "optimizer.exclude_from_weight_decay(var_names=['batch_normalization', 'bias', 'head_supervised'])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=macro_soft_f1,\n",
    "    metrics=[macro_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8effb001-1aed-418b-a90b-7f19dd7f9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"out/board/fit\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c94748d-4eb3-41bb-bc73-4f4eefc00f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_train(x, y, info=None):\n",
    "    x = preprocess_image(\n",
    "        x, *IMAGE_SIZE,\n",
    "        is_training=True, color_distort=False, crop='Center')\n",
    "    return x, y\n",
    "\n",
    "def _preprocess_val(x, y, info=None):\n",
    "    x = preprocess_image(\n",
    "        x, *IMAGE_SIZE,\n",
    "        is_training=False, color_distort=False, crop='Center')\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96371966-9723-403d-aa8a-cf6c6873952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customLoader = MIMIC_CXR_JPG_Loader({'train': 10, 'validate': 5, 'test': 0}, project_folder)\n",
    "train_tfds, val_tfds, test_tfds = customLoader.load()\n",
    "\n",
    "train_tfds = train_tfds.shuffle(buffer_size=2*BATCH_SIZE)\n",
    "batched_train_tfds = train_tfds.map(_preprocess_train).batch(BATCH_SIZE)\n",
    "\n",
    "val_tfds = val_tfds.shuffle(buffer_size=2*BATCH_SIZE)\n",
    "batched_val_tfds = val_tfds.map(_preprocess_val).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64db0a4-379b-482b-8283-b8aa35cc3b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 12:47:52.262624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-02-14 12:47:53.621084: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fe7563a5850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-14 12:47:53.621112: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2024-02-14 12:47:53.624602: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-14 12:47:53.702666: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 23s 3s/step - loss: 0.8571 - macro_f1: 0.1220 - val_loss: 0.8257 - val_macro_f1: 0.1357\n",
      "\n",
      "Training took 0h:0m:23s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "history = model.fit(batched_train_tfds,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=batched_val_tfds,\n",
    "                callbacks=[tensorboard_callback])\n",
    "print('\\nTraining took {}'.format(print_time(time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a0e83b-3b15-44db-abcb-61ce28fdfbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "2024-02-14 12:52:12.455967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
       "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
       "2024-02-14 12:52:13.015760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
       "2024-02-14 12:52:13.015847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
       "2024-02-14 12:52:13.015870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
       "2024-02-14 12:52:13.642029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
       "2024-02-14 12:52:13.646846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
       "2024-02-14 12:52:13.647035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "Address already in use\n",
       "Port 8008 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=out/board --host=localhost --port=8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09ee33d-be9c-4363-8875-221dfbb1734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, input_1) at 0x7FE89F618CD0>})\n",
      "Model Imported. Visualize by running: tensorboard --logdir=./out/board/vis_remedis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:41:09.105137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 13:41:09.105443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 13:41:09.105657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 13:41:09.105871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 13:41:09.106050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-14 13:41:09.106180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10399 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.python.framework import importer\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.summary import summary\n",
    "from tensorflow.python.client import session\n",
    "\n",
    "project_folder = os.getcwd()\n",
    "log_dir = './out/board/vis_remedis' #where to save your tensorboard event file\n",
    "model_handle = project_folder + '/base-models/remedis/cxr-50x1-remedis-m/'\n",
    "\n",
    "model = hub.load(model_handle)  #Import your tf hub model here\n",
    "print(model.signatures)\n",
    "\n",
    "#the signature here is 'default'.  you can figure you what yours is by calling 'model.signatures' and checking the output (e.g. _SignatureMap({'default': <tensorflow.python.eager.wrap_function.WrappedFunction object...)\n",
    "\n",
    "model_graphdef = model.signatures['serving_default'].graph.as_graph_def() \n",
    "\n",
    "with session.Session(graph=ops.Graph()) as sess:\n",
    "  input_graph_def = model_graphdef\n",
    "  \n",
    "  importer.import_graph_def(input_graph_def)\n",
    "\n",
    "  pb_visual_writer = summary.FileWriter(log_dir)\n",
    "  pb_visual_writer.add_graph(sess.graph)\n",
    "  print(\"Model Imported. Visualize by running: \"\n",
    "        \"tensorboard --logdir={}\".format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82368c87-8da7-4afe-8639-8b4be7e7612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-14 13:50:09.349947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-14 13:50:09.914698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-02-14 13:50:09.914803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64:/home/payam/miniconda3/envs/tf2-gpu/lib/\n",
      "2024-02-14 13:50:09.914828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/samba/research/shield/projects/payamfz/medical-ssl-segmentation/finetuning2.py\", line 35, in <module>\n",
      "    import tensorflow_datasets as tfds\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/__init__.py\", line 42, in <module>\n",
      "    import tensorflow_datasets.core.logging as _tfds_logging\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/__init__.py\", line 22, in <module>\n",
      "    from tensorflow_datasets.core import community\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/community/__init__.py\", line 18, in <module>\n",
      "    from tensorflow_datasets.core.community.huggingface_wrapper import mock_builtin_to_use_gfile\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/community/huggingface_wrapper.py\", line 31, in <module>\n",
      "    from tensorflow_datasets.core import dataset_builder\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 34, in <module>\n",
      "    from tensorflow_datasets.core import dataset_info\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py\", line 50, in <module>\n",
      "    from tensorflow_datasets.core import splits as splits_lib\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/splits.py\", line 34, in <module>\n",
      "    from tensorflow_datasets.core import proto as proto_lib\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/proto/__init__.py\", line 18, in <module>\n",
      "    from tensorflow_datasets.core.proto import dataset_info_generated_pb2 as dataset_info_pb2  # pylint: disable=line-too-long\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_datasets/core/proto/dataset_info_generated_pb2.py\", line 31, in <module>\n",
      "    from tensorflow_metadata.proto.v0 import schema_pb2 as tensorflow__metadata_dot_proto_dot_v0_dot_schema__pb2\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_metadata/proto/__init__.py\", line 16, in <module>\n",
      "    from tensorflow_metadata.proto.v0 import anomalies_pb2\n",
      "  File \"/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/tensorflow_metadata/proto/v0/anomalies_pb2.py\", line 5, in <module>\n",
      "    from google.protobuf.internal import builder as _builder\n",
      "ImportError: cannot import name 'builder' from 'google.protobuf.internal' (/home/payam/miniconda3/envs/tf2-gpu/lib/python3.9/site-packages/google/protobuf/internal/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "!python finetuning2.py --dataset=MIMIC-CXR \\\n",
    "  --base_model_path=./base-models/remedis/cxr-50x1-remedis-m/ \\\n",
    "  --epochs=2 --batch_size=4 --learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94eba9-78d6-4a04-bb94-1f3811be12cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
